{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Pipeline(object):\n",
      "    \"\"\"\n",
      "    A data processing pipeline.\n",
      "      \n",
      "    A pipeline consists of exactly one data \"source\", which pulls data\n",
      "    from disk / network / a device; and an arbitrary number of \"nodes\"\n",
      "    which process data in sequence or export the data to disk.\n",
      "    \n",
      "    Each processing node has a set of preconditions (e.g. gaps must be\n",
      "    filled) and a set of postconditions (e.g. gaps will have been\n",
      "    filled).  This allows us to check that a particular pipeline is\n",
      "    viable (i.e. that, for every node, the node's preconditions are\n",
      "    satisfied by an upstream node or by the source).\n",
      "    \n",
      "    Internally, the pipeline is represented by a directed acyclic\n",
      "    graphical model (DAG).\n",
      "    \n",
      "    DEVELOPMENT PLANS: \n",
      "    A pipeline could fork into multiple parallel\n",
      "    pipelines.  Data and metadata would be copied to each fork and\n",
      "    each sub-pipeline would be run as a separate process (after\n",
      "    checking requirements for each subpipeline as the start).\n",
      "    \n",
      "    Pipelines could be saved/loaded from disk; or rendered\n",
      "    graphically.  In the future it would be nice to have a full\n",
      "    graphical UI (like Node-RED).\n",
      "    \n",
      "    Attributes\n",
      "    ----------\n",
      "    chain : networkx DAG containing all the processing nodes\n",
      "    source : Source\n",
      "    \"\"\"\n",
      "    def __init__(self):\n",
      "        self.instances = {}\n",
      "    \n",
      "    def insert_node(self, node):\n",
      "        # Insert node into the grahical model\n",
      "        node.instance = self.instances.get(node.name, 1)\n",
      "        self.instances[node.name] += 1\n",
      "    \n",
      "    def start(self):\n",
      "        # Reset\n",
      "        for node in self.nodes:\n",
      "            node.reset()\n",
      "        \n",
      "        # Check requirements\n",
      "        condition = self.source.condition()\n",
      "\n",
      "        # for example, `condition` might represent:\n",
      "        # * [measurements] are available\n",
      "        # * gaps = Gaps([(\"2013-01-01 00:00\", \"2013-01-01 00:10\"), ...])\n",
      "        # * zeros have been inserted\n",
      "        # * sample_period = 1 second (I was thinking of putting this\n",
      "        #   in a separate, imutable 'metadata' field but sample_period\n",
      "        #   could be changed during the pipeline by an\n",
      "        #   up/down-sampling node)\n",
      "\n",
      "        for node in self.nodes: # go through the nodes in order, starting upstream\n",
      "            unsatisfied_preconditions = condition.unsatisfied_preconditions(node.preconditions)\n",
      "            if unsatisfied_preconditions:\n",
      "                raise Exception(str(unsatisfied_preconsitions))\n",
      "                # TODO: should explain exactly why preconditions aren't satisfied\n",
      "                # e.g. which node is unsatisfied? Precisely which preconditions aren't met?\n",
      "            condition.update(node.postconditions)\n",
      "            # for example, `condition` might now include:\n",
      "            # * total energy for this chunk has been calculated\n",
      "            # * from [measurements] available, we must load reactive power and active power\n",
      "\n",
      "        # Load data and run processing\n",
      "        n_buffer_nodes = len([node for node in nodes if node.is_buffer])\n",
      "        for i in range(n_buffer_nodes):\n",
      "            for df in self.source.load(conditions.measurements()):\n",
      "                for node in nodes:\n",
      "                    df = node.process(df)\n",
      "                    if node.is_buffer and not node.is_full():\n",
      "                        break\n",
      "                # TODO: handle forks in pipeline???\n",
      "                \n",
      "            unfull_buffers = [node for node in nodes if node.is_buffer and not node.is_full()]\n",
      "            unfull_buffers[0].finish()\n",
      "                \n",
      "        # Do any tidying up required\n",
      "        for node in nodes:\n",
      "            node.finish()            \n",
      "\n",
      "class Source(object):\n",
      "    def load(self, measurements):\n",
      "        \"\"\"Returns a generator.  Each item returned by the generator\n",
      "        is a pd.DataFrame with metadata attached (sample period, gaps,\n",
      "        gaps_bookended_with_zeros etc).\"\"\"\n",
      "    \n",
      "    def condition(self):\n",
      "        return Condition()\n",
      "        \n",
      "\n",
      "class Condition(object):\n",
      "    \"\"\"Stores pre-conditions and post-conditions.\n",
      "    \n",
      "    Requirements can be of the form:\n",
      "    \n",
      "    \"node X needs (power.apparent or power.active) (but not\n",
      "    power.reactive) and voltage is useful but not essential\"\n",
      "    \n",
      "    or\n",
      "    \n",
      "    \"node Y needs everything available from disk (to save to a copy to\n",
      "    disk)\"\n",
      "    \n",
      "    or\n",
      "    \n",
      "    \"ComputeEnergy node needs gaps to be bookended with zeros\" (if\n",
      "    none of the previous nodes provide this service then check\n",
      "    source.metadata to see if zeros have already been inserted; if the\n",
      "    haven't then raise an error to tell the user to add a\n",
      "    BookendGapsWithZeros node.)\n",
      "    \"\"\"\n",
      "\n",
      "    def update(self, postconditions):\n",
      "        \"\"\"Add postconditions to self.\"\"\"\n",
      "        pass\n",
      "    \n",
      "    def unsatisfied_preconditions(self, preconditions):\n",
      "        \"\"\"Returns list of preconditions not satisfied by self.\"\"\"\n",
      "        \n",
      "\n",
      "class Node(object):\n",
      "    \"\"\"Abstract class defining interface for all Node subclasses,\n",
      "    where a 'node' is a module which runs pre-processing or statistics\n",
      "    or NILM training or disaggregation.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "\n",
      "    @classmethod\n",
      "    def preconditions(self):\n",
      "        return preconditions\n",
      "    \n",
      "    @classmethod\n",
      "    def postconditions(self):\n",
      "        return postconditions\n",
      "    \n",
      "    def process(self, df):\n",
      "        # do stuff to df\n",
      "        return df\n",
      "    \n",
      "#-------------- RESULT CLASSES -----------------#\n",
      "\n",
      "\"\"\"Metadata results from each node need to be assigned to a specific\n",
      "class so we know how to combine results from multiple chunks.  For\n",
      "example, Energy can be simply summed; while dropout rate should be\n",
      "averaged, and gaps need to be merged across chunk boundaries.  Results\n",
      "are a subclass of DataFrame.  The index is the start timestamp for\n",
      "which the results are valid; the first column ('end') is the end\n",
      "timestamp for which the results are valid.  Other columns are the\n",
      "results.  \"\"\"\n",
      "\n",
      "class Results(pd.DataFrame):\n",
      "    def combined(self):\n",
      "        \"\"\"Return all results from each chunk combined\"\"\"\n",
      "\n",
      "class EnergyResults(Results):\n",
      "    def combined(self):\n",
      "        return self.sum()\n",
      "\n",
      "#-------------- STATS NODES --------------------#\n",
      "    \n",
      "class StatsNode(Object):\n",
      "    \"\"\"\n",
      "    Abstract class for nodes which process statistics\n",
      "    \"\"\"\n",
      "    def results(self):\n",
      "        pass\n",
      "\n",
      "\n",
      "class LocateGapsNode(Node, StatsNode):\n",
      "    \n",
      "    @classmethod\n",
      "    def preconditions(self):\n",
      "        # Needs sample period to be set\n",
      "        # must be followed by a buffer node or an export node\n",
      "        \n",
      "    @classmethod\n",
      "    def postconditions(self):\n",
      "        # Gaps will be identified!\n",
      "\n",
      "class EnergyNode(Node, StatsNode):\n",
      "    \"\"\"Computes energy\"\"\"\n",
      "\n",
      "    name = 'energy'\n",
      "\n",
      "    @classmethod\n",
      "    def preconditions(self):\n",
      "        # Needs any power or energy measurements.  Preference is for\n",
      "        # energy measurements.  Computes energy for each of {active,\n",
      "        # reactive, apparent} available If only power measurements are\n",
      "        # available and if there are gaps then requires zeros to be\n",
      "        # inserted before gaps.\n",
      "        \n",
      "    @classmethod\n",
      "    def postconditions(self):\n",
      "        # Energy is calculated\n",
      "        pass\n",
      "           \n",
      "    def process(self, df):\n",
      "        # TODO: calculate energy_for_df\n",
      "        df.metadata[(self.name, self.instance)] = EnergyResults(energy_for_df)\n",
      "        return df\n",
      "    \n",
      "    def results(self):\n",
      "        return self._cumulator\n",
      "\n",
      "class ProportionEnergySubmeteredNode(Node, StatsNode):\n",
      "    def preconditions(self):\n",
      "        \"\"\"\n",
      "        * use the gaps in mains as a mask\n",
      "        * then calculate energy\n",
      "        \"\"\"\n",
      "\n",
      "#---------------- PROCESSING NODES --------------------#\n",
      "\n",
      "class ProcessingNode(Object):\n",
      "    \"\"\"\n",
      "    Abstract class for nodes which process data\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "class BookendGapsWithZerosNode(Node, ProcessingNode):\n",
      "    \n",
      "    def preconditions(self):\n",
      "        \"\"\"Requires gaps to be located.\"\"\"\n",
      "        \n",
      "    def postconditions(self):\n",
      "        \"\"\"Bookends gaps with zeros\"\"\"\n",
      "    \n",
      "    def process(self, df):\n",
      "        for gap_start, gap_end in df.metadata.gaps:\n",
      "            # insert zeros!\n",
      "            \n",
      "        return df\n",
      "    \n",
      "#--------------- EXPORT NODES --------------------#\n",
      "\n",
      "class ExportNode(Object):\n",
      "    \"\"\"\n",
      "    Abstract class for nodes which export data to disk / network etc\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "#--------------- BUFFER NODES ---------------------#\n",
      "\n",
      "class BufferNode(Node):\n",
      "    \"\"\"BufferNodes solve the following problem. Say we need to run the\n",
      "    chain on a dataset too large to fit in memory and we have a\n",
      "    processing chain like this:\n",
      "    \n",
      "    Source -> find gaps -> split on gaps -> calculate dropout rate\n",
      "    \n",
      "    In this case, we only have full knowledge of where the gaps are\n",
      "    once we have looked at all chunks.  A BufferNode forces the\n",
      "    Pipeline to run all chunks through the pipeline up to the Buffer\n",
      "    (and \"finish\" all metadata) before proceeding.\n",
      "    \n",
      "    Source -> find gaps -> BufferNode -> split on gaps -> calculate dropout rate\n",
      "    \n",
      "    BufferNode passed just the metadata onto the next stage.\n",
      "    \n",
      "    QUESTION: BufferNodes will always be proceeded by splitter nodes\n",
      "    so maybe they should be combined?\n",
      "    \n",
      "    QUESTION: Splitter nodes will need direct access to the Source.\n",
      "    How to implement this?  Maybe pass in a ref to Source to all\n",
      "    Nodes???\n",
      "    \n",
      "    QUESTION: maybe this is over complex???  Maybe we should force\n",
      "    users to first run\n",
      "    \n",
      "    Source('a.h5') -> find gaps -> export('a.h5')\n",
      "    \n",
      "    And then do\n",
      "    \n",
      "    Source('a.h5') -> split on gaps -> ...\n",
      "    \"\"\"\n"
     ],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}