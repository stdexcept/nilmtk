{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Pipeline(object):\n",
      "    \"\"\"\n",
      "    A data processing pipeline.\n",
      "      \n",
      "    A pipeline consists of exactly one data \"source\", which pulls data from disk / network / a device;\n",
      "    and an arbitrary number of \"nodes\" which process data in sequence or export the data to disk.\n",
      "    \n",
      "    Each processing node has a set of preconditions (e.g. gaps must be filled) and a set\n",
      "    of postconditions (e.g. gaps will have been filled).  This allows us to \n",
      "    check that a particular pipeline is viable (i.e. that, for every node,\n",
      "    the node's preconditions are satisfied by an upstream node or by the source).\n",
      "    \n",
      "    Internally, the pipeline is represented by a directed acyclic graphical model (DAG).\n",
      "    \n",
      "    A pipeline can fork into multiple parallel pipelines.  Data and metadata are copied to each fork\n",
      "    and each sub-pipeline is run as a separate process.\n",
      "    \n",
      "    Pipelines can be saved/loaded from disk; or rendered it graphically.  In the future it would\n",
      "    be nice to have a full graphical UI (like Node-RED).\n",
      "    \n",
      "    Attributes\n",
      "    ----------\n",
      "    chain : networkx DAG containing all the processing nodes\n",
      "    source : Source\n",
      "    \"\"\"\n",
      "    \n",
      "    def insert_node(self, node):\n",
      "        # Insert node into the grahical model\n",
      "        pass\n",
      "    \n",
      "    def start(self):\n",
      "        # Check requirements\n",
      "        requirements = Requirements()\n",
      "        for node in self.nodes:\n",
      "            node.reset()\n",
      "            requirements.update(node.requires())\n",
      "\n",
      "        # Load data and run processing\n",
      "        for df in self.source.load(requirements):\n",
      "            for node in nodes:\n",
      "                df = node.process(df)\n",
      "                # TODO: branching???\n",
      "                \n",
      "        # Do any tidying up required\n",
      "        for node in nodes:\n",
      "            node.finish()\n",
      "            \n",
      "\n",
      "class Source(object):\n",
      "    def load(self, requirements):\n",
      "        \"\"\"Returns an generator.  Each item returned by the generator is a pd.DataFrame with\n",
      "        metadata attached (sample period, gaps, gaps_bookended_with_zeros etc).  If it\n",
      "        cannot satisfy the hard requirements then raise an exception.\"\"\"\n",
      "            \n",
      "\n",
      "class Requirements(object):\n",
      "    \"\"\"Stores the union of requirements from multiple nodes.\n",
      "    Requirements are of the form \n",
      "    \n",
      "    \"node X needs (power.apparent or power.active) (but not power.reactive)\n",
      "    and voltage is useful but not essential\" \n",
      "    \n",
      "    or \n",
      "    \n",
      "    \"node Y needs everything available (to save to disk)\"\n",
      "    \n",
      "    or\n",
      "    \n",
      "    \"ComputeEnergy node needs gaps to be bookended with zeros\" (if none of the previous nodes\n",
      "    provide this service then check source.metadata to see if zeros have already been inserted;\n",
      "    if the haven't then raise an error to tell the user to add a BookendGapsWithZeros node.)\n",
      "    \n",
      "    If we split processing (to run on multiple cores) then we can ask each subchain what it requires\n",
      "    before we copy the data at the branch point.\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "class Provides(object):\n",
      "    \"\"\"Nodes and Sources can provide data in a certain state,\n",
      "    e.g. with gaps bookended with zeros\n",
      "    \"\"\"\n",
      "    \n",
      "    def satisfies(self, requirement):\n",
      "        \"\"\"Returns boolean\"\"\"\n",
      "        \n",
      "\n",
      "class Node(object):\n",
      "    \"\"\"\n",
      "    Abstract class defining interface for all Node subclasses, \n",
      "    where a 'node' is a module which runs pre-processing or statistics or NILM training or disaggregation.\n",
      "    \"\"\"\n",
      "    def __init__(self, flow=None):\n",
      "        self.flow = flow\n",
      "        self.reset()\n",
      "    \n",
      "    def reset(self):\n",
      "        pass\n",
      "    \n",
      "    def requires(self):\n",
      "        return requirements\n",
      "    \n",
      "    def provides(self):\n",
      "        return provides\n",
      "    \n",
      "    def process(self, df):\n",
      "        # do stuff to df\n",
      "        return df\n",
      "\n",
      "#-------------- STATS NODES --------------------#\n",
      "    \n",
      "class StatsNode(Object):\n",
      "    \"\"\"\n",
      "    Abstract class for nodes which process statistics\n",
      "    \"\"\"\n",
      "    def results(self):\n",
      "        pass\n",
      "\n",
      "class EnergyNode(Node, StatsNode):\n",
      "    \"\"\"Computes energy\"\"\"\n",
      "    \n",
      "    def requires(self):\n",
      "        # Needs any power or energy measurements.  Preference is for energy measurements.\n",
      "        # Computes energy for each of {active, reactive, apparent}\n",
      "        # If only power measurements are available and if there are gaps then requires\n",
      "        # zeros to be inserted before gaps.\n",
      "        \n",
      "    def reset(self):\n",
      "        self._first_chunk = True\n",
      "        self._cumulator = {}\n",
      "        \n",
      "    def _initialise_cumulator(self, measurements):\n",
      "        \"\"\"\n",
      "        Configures cumulator with a key for each of {active, reactive, apparent} available\n",
      "        in the measurements \n",
      "        \"\"\"\n",
      "        for m in ['active', 'reactive', 'apparent']:\n",
      "            if ('power', m) in measurements or ('energy', m) in measurements:\n",
      "                self._cumulator[m] = 0\n",
      "        \n",
      "    def process(self, df):\n",
      "        if self._first_chunk:\n",
      "            self._initialise_cumulator(df.columns)\n",
      "            self._first_chunk = False\n",
      "            \n",
      "        # TODO: increment each cumulator\n",
      "        # attach metadata to df recording this df's energy\n",
      "        return df # pass-through\n",
      "    \n",
      "    def results(self):\n",
      "        return self._cumulator\n",
      "\n",
      "class ProportionEnergySubmeteredNode(Node, StatsNode):\n",
      "    def requires(self):\n",
      "        \"\"\"\n",
      "        * use the gaps in mains as a mask\n",
      "        * then calculate energy\n",
      "        \"\"\"\n",
      "\n",
      "#---------------- PROCESSING NODES --------------------#\n",
      "\n",
      "class ProcessingNode(Object):\n",
      "    \"\"\"\n",
      "    Abstract class for nodes which process data\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "class BookendGapsWithZeros(Node, ProcessingNode):\n",
      "    \n",
      "    def requires(self):\n",
      "        \"\"\"Requires gaps to be located.\"\"\"\n",
      "        \n",
      "    def provides(self):\n",
      "        \"\"\"Bookends gaps with zeros\"\"\"\n",
      "    \n",
      "    def process(self, df):\n",
      "        for gap_start, gap_end in df.metadata.gaps:\n",
      "            # insert zeros!\n",
      "            \n",
      "        return df\n",
      "    \n",
      "#--------------- EXPORT NODES --------------------#\n",
      "\n",
      "class ExportNode(Object):\n",
      "    \"\"\"\n",
      "    Abstract class for nodes which export data to disk / network etc\n",
      "    \"\"\"\n",
      "    pass\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}