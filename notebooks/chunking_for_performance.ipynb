{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function, division\n",
      "import numpy as np\n",
      "\n",
      "# Create a big numpy array\n",
      "N = 1E7\n",
      "arr = np.random.randn(N)\n",
      "print(arr[:5])\n",
      "print('dtype=', arr.dtype)\n",
      "print('MBytes=', N*8 / 1E6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-1.40028989  0.51319398 -0.95821242  0.08248267 -1.1760342 ]\n",
        "dtype= float64\n",
        "MBytes= 80.0\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clip(data):\n",
      "    return data.clip(0.4,0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chunk_by_chunk_clip(data):\n",
      "    # n_chunks = 80 * 16 # 64KB fits into L1 = 16.2 ms per loop\n",
      "    # n_chunks = 80 * 4 # 256KB fits into L2 = 1.54 ms per loop\n",
      "    # n_chunks = 80 # 1MB = 0.367 ms\n",
      "    n_chunks = 40 # 2MB = 0.345 ms\n",
      "    # n_chunks = 90 // 3 # 3MB = 0.428 ms\n",
      "    chunk_len = N // n_chunks\n",
      "    # print('MBytes per chunk= {:.3f}MB'.format(chunk_len * 8 / 1E6))\n",
      "    boundaries = np.arange(0, N, n_chunks, dtype=np.uint)\n",
      "    for i in range(n_chunks):\n",
      "        chunk = data[boundaries[i]:boundaries[i+1]]\n",
      "        chunk = chunk.clip(0.4,0.5)\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit clip(arr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 129 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit chunk_by_chunk_clip(arr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 362 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OK, now let's try with pandas\n",
      "import pandas as pd\n",
      "\n",
      "series = pd.Series(arr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit clip(series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 295 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit clip(series.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 128 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit chunk_by_chunk_clip(series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 69.6 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit chunk_by_chunk_clip(series.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 328 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# and let's try doing some pandas operations\n",
      "\n",
      "def rolling_mean(data):\n",
      "    return pd.rolling_mean(data, 30)\n",
      "\n",
      "def chunk_by_chunk_rolling_mean(data):\n",
      "    # n_chunks = 80 * 16 # 64KB fits into L1 = 16.2 ms per loop\n",
      "    # n_chunks = 80 * 4 # 256KB fits into L2 = 1.54 ms per loop\n",
      "    # n_chunks = 80 # 1MB = 0.367 ms\n",
      "    n_chunks = 40 # 2MB = 0.345 ms\n",
      "    # n_chunks = 90 // 3 # 3MB = 0.428 ms\n",
      "    chunk_len = N // n_chunks\n",
      "    # print('MBytes per chunk= {:.3f}MB'.format(chunk_len * 8 / 1E6))\n",
      "    boundaries = np.arange(0, N, n_chunks, dtype=np.uint)\n",
      "    for i in range(n_chunks):\n",
      "        chunk = data.iloc[boundaries[i]:boundaries[i+1]]\n",
      "        chunk = pd.rolling_mean(chunk, 30)\n",
      "    return data\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit rolling_mean(series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 219 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit chunk_by_chunk_rolling_mean(series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 8.22 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "series32 = series.astype(np.float32)\n",
      "%timeit chunk_by_chunk_rolling_mean(series32)\n",
      "# but if we double the chunk size then we get 5 ms per loop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 9.04 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's try multiple ops per chunk\n",
      "\n",
      "def rolling_mean_and_clip(data):\n",
      "    data = pd.rolling_mean(data, 30)\n",
      "    data = data.values.clip(0.4,0.5)\n",
      "    return data\n",
      "\n",
      "def chunk_by_chunk_rolling_mean_and_clip(data):\n",
      "    # n_chunks = 80 * 16 # 64KB fits into L1 = 16.2 ms per loop\n",
      "    # n_chunks = 80 * 4 # 256KB fits into L2 = 1.54 ms per loop\n",
      "    # n_chunks = 80 # 1MB = 0.367 ms\n",
      "    n_chunks = 40 # 2MB = 0.345 ms\n",
      "    # n_chunks = 90 // 3 # 3MB = 0.428 ms\n",
      "    chunk_len = N // n_chunks\n",
      "    # print('MBytes per chunk= {:.3f}MB'.format(chunk_len * 8 / 1E6))\n",
      "    boundaries = np.arange(0, N, n_chunks, dtype=np.uint)\n",
      "    for i in range(n_chunks):\n",
      "        chunk = data.iloc[boundaries[i]:boundaries[i+1]]\n",
      "        chunk = pd.rolling_mean(chunk, 30)\n",
      "        chunk = chunk.values.clip(0.4,0.5)\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit rolling_mean_and_clip(series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 342 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit chunk_by_chunk_rolling_mean_and_clip(series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100 loops, best of 3: 9.19 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Conclusions\n",
      "\n",
      "Yes, it can be hugely faster to process data in 2MB chunk sizes (my L3 cache is 3MB)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}